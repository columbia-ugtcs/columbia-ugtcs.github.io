<!DOCTYPE html>
<html lang="en" class="no-js">

<head>
    <!--Website Google searchability-->
    <meta name="google-site-verification" content="xvD194KsBxeaW40tr48z5nGiEF-zbgEgpTNHhK2AMu8" />
    <!-- Mobile Specific Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Favicon-->
    <link rel="shortcut icon" href="img/fav.png">
    <!-- Author Meta -->
    <meta name="author" content="Clayton">
    <!-- Meta Description -->
    <meta name="description" content="">
    <!-- Meta Keyword -->
    <meta name="keywords" content="">
    <!-- meta character set -->
    <meta charset="UTF-8">
    <!-- Site Title -->
    <title>Columbia Undergraduate Learning Seminar in Theoretical Computer Science</title>
    <link rel="stylesheet" href="undergrad-seminar-style.css">
    <!--Fonts-->
    <link href="https://fonts.googleapis.com/css?family=Istok+Web|Roboto+Slab&display=swap" rel="stylesheet">
    <!--Favicon-->
    <link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
    <link rel="manifest" href="favicon/site.webmanifest">
    <link rel="mask-icon" href="favicon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <!-- Script -->
    <script type="text/javascript">
    function toggle_visibility(id) {
        var e = document.getElementById(id);
        if (e.style.display == 'block')
            e.style.display = 'none';
        else
            e.style.display = 'block';
    }
    //-->
    </script>
</head>

<body>
    <h1>Columbia Undergraduate Learning Seminar in Theoretical Computer Science</h1>
   
    <h2>About</h2>
    <p>The Columbia Undergraduate Learning Seminar in Theoretical Computer Science is a student-run seminar for undergraduates at Columbia interested in theoretical computer science. The goal of the learning seminar is to provide undergraduate students with the opportunity to learn about theoretical computer science in a collaborative, student-driven setting and to meet other students interested in theoretical computer science.
    </p>
    <p>
    The learning seminar is dedicated to providing an inclusive and welcoming environment for all students interested in theoretical computer science. No background in theoretical computer science is required to participate in the seminar, and everyone is welcome to join!
    </p>   
    <p>
    Each semester, the Columbia Undergraduate Learning Seminar in Theoretical Computer Science will hold one or more seminars on topics related to TCS. The presentations will primarily be given by students, which is a great opportunity to gain experience giving a technical talk in TCS.
    </p>
    <hr>
    <h2>Join Us!</h2>
    <p>The seminar is currently run by Ekene Ezeunala. If you have any questions or would like to join the seminar's Slack channel, please email him <a href="mailto:efe2110@columbia.edu?subject=%5BUndergrad TCS Seminar%5D">here</a>.
    </p>
    <p>Sign up for the mailing list here: <a href="https://forms.gle/8peARsv9VyQMz3wz7">Mailing List Sign-Up</a>.
    </p>
   

    <hr>
    <h2> Fall 2023
    </h2>
    <div id='fall23' style="display: block;">
        <p>This Fall semester, we will be holding three groups, each focused on a different topic within TCS. The groups are: Algebraic and Spectral Graph Theory, Analysis of Boolean Functions, and Theoretical Neuroscience. Each group is run by an undergraduate student organizer along with a graduate student mentor. The groups meet roughly weekly and should be approachable for students of all ranges of prior exposure to TCS.</p>
        <p>Please see the descriptions and tables below for a summary and the list of talks for each of the groups.</p>

        <div class='fall23-group'>
            <h3>Algebraic and Spectral Graph Theory</h3>
            <p>Organizer: Ekene. Graduate Student Mentor: Binghui.</p>
            <p><b>Description:</b> We explore a variety of topics in spectral and algebraic graph theory, following the book of the same name by Daniel Spielman. Some of the topics we will cover include random walks, rubber bands, and electronic networks. The seminar will build up towards a discussion of one of the seminal results in this area, a fast algorithm for solving linear systems.</p>
            <div style="height: 10px;"></div>
            <table>
                <tr>
                    <th>Resource</th>
                    <th>Title</th>
                    <th>Link</th>
                </tr>
                <tr>
                    <td>Spielman</td>
                    <td>Spectral and Algebraic Graph Theory</td>
                    <td><a href="http://cs-www.cs.yale.edu/homes/spielman/sagt/">Link</a></td>
                </tr>
            </table>
            <div style="height: 30px;"></div>
            <table>
                <tr>
                    <th>Date</th>
                    <th>Topic</th>
                    <th>Speaker</th>
                    <th>Reading</th>
                </tr>
                <tr>
                    <td>September 30th</td>
                    <td>Introduction, Motivation, and Background. The Spectral Theorem.</td>
                    <td>Ekene</td>
                    <td>Spielman Chap. 1; <a href="https://mathweb.ucsd.edu/~fan/research/cbms.pdf">Fan R. K. Chung Lectures on Spectral Graph Theory Chap. 1</a></td>
                </tr>
                <tr>
                    <td>October 7th</td>
                    <td>Courant-Fischer Theorem. The graph Laplacian.</td>
                    <td></td>
                    <td>Spielman Chaps. 2, 3</td>
                </tr>
                <tr>
                    <td>October 14th</td>
                    <td>Random Walk</td>
                    <td>Adi</td>
                    <td>Spielman Chap. 10</td>
                </tr>
                <tr>
                    <td>October 21st</td>
                    <td>Electronic Networks and Graphs</td>
                    <td></td>
                    <td>Spielman Chaps. 11, 12</td>
                </tr>
                <tr>
                    <td>October 28th</td>
                    <td><i>Midterm Break</i></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>November 4th</td>
                    <td>Sampling Spanning Trees</td>
                    <td>Casey</td>
                    <td>Spielman Chap. 13</td>
                </tr>
                <tr>
                    <td>November 11th</td>
                    <td>Graph Sparsifiers</td>
                    <td>Binghui</td>
                    <td>Spielman Chap. 14</td>
                </tr>
                <tr>
                    <td>November 18th</td>
                    <td>Cheeger Inequality and Expanders</td>
                    <td>Lyra</td>
                    <td>Spielman Chap. 21</td>
                </tr>
                <tr>
                    <td>December 2nd</td>
                    <td>Laplacian solvers, and a nearly-linear-time Laplacian Solver</td>
                    <td>Ekene and Binghui</td>
                    <td>Spielman Chap. 36; [<a href="https://dl.acm.org/doi/abs/10.1145/1007352.1007372">ST'04</a>]; [<a href="https://ieeexplore.ieee.org/abstract/document/6108220/">KMP'10</a>]; [<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611973402.16">KLOS'14</a>]; [<a href="https://ieeexplore.ieee.org/abstract/document/7782974/">Madry'13</a>]</td>
                </tr>
            </table>
        </div>

        <div class='fall23-group'>
            <h3>Analysis of Boolean Functions</h3>
            <p>Organizer: Ashwin and Krish. Graduate Student Mentor: Yuhao.</p>
            <p><b>Description:</b> We cover foundational concepts in Boolean function analysis, a widely applicable tool in theoretical computer science. We will go through the first two chapters of Ryan O'Donnell's <i>Analysis of Boolean Functions</i> textbook, culminating in an algorithm for linearity testing and a result in voting theory.</p>
            <div style="height: 10px;"></div>
            <table>
                <tr>
                    <th>Resource</th>
                    <th>Title</th>
                    <th>Link</th>
                </tr>
                <tr>
                    <td>O'Donnell</td>
                    <td>Analysis of Boolean Functions</td>
                    <td><a href="https://www.cs.cmu.edu/~odonnell/papers/Analysis-of-Boolean-Functions-by-Ryan-ODonnell.pdf">Link</a></td>
                </tr>
            </table>
            <div style="height: 30px;"></div>
            <table>
                <tr>
                    <th>Date</th>
                    <th>Topic</th>
                    <th>Speaker</th>
                    <th>Reading</th>
                </tr>
                <tr>
                    <td>October 2nd</td>
                    <td>Background</td>
                    <td>Krish and Ashwin</td>
                    <td>O'Donnell Sec. 1.1 - 1.3</td>
                </tr>
                <tr>
                    <td>October 9th</td>
                    <td>Parseval's Identity</td>
                    <td></td>
                    <td>O'Donnell Sec. 1.4</td>
                </tr>
                <tr>
                    <td>October 16th</td>
                    <td>Convolution</td>
                    <td></td>
                    <td>O'Donnell Sec. 1.5</td>
                </tr>
                <tr>
                    <td>October 23rd</td>
                    <td>BLR Linearity Test</td>
                    <td></td>
                    <td>O'Donnell Sec. 1.6</td>
                </tr>
                <tr>
                    <td>October 30th</td>
                    <td>Influences and Derivatives</td>
                    <td></td>
                    <td>O'Donnell Sec. 2.12 - 2.22</td>
                </tr>
                <tr>
                    <td>November 6th</td>
                    <td><i>Academic Holiday</i></td>
                    <td></td>
                    <td></td>
                </tr>
                <tr>
                    <td>November 13th</td>
                    <td>Poincare Inequality</td>
                    <td></td>
                    <td>O'Donnell Sec. 2.27 - 2.38</td>
                </tr>
                <tr>
                    <td>November 20th</td>
                    <td>Noise Stability</td>
                    <td></td>
                    <td>O'Donnell Sec. 2.40 - 2.47</td>
                </tr>
                <tr>
                    <td>November 27th</td>
                    <td>The Noise Operator</td>
                    <td></td>
                    <td>O'Donnell Sec. 2.49 - 2.54</td>
                </tr>
                <tr>
                    <td>December 4th</td>
                    <td>Arrow's Theorem</td>
                    <td></td>
                    <td>O'Donnell Sec. 2.5</td>
                </tr>
            </table>
        </div>
        <div class='fall23-group'>
            <h3>Theoretical Neuroscience and Artificial Intelligence</h3>
            <p>Organizer: Shujun. Graduate Student Mentor: Daniel.</p>
            <p><b>Description:</b> We explore topics in theoretical neuroscience as it relates to artificial intelligence. Talks themselves will focus on the mathematical and computational cores of the weekly topic, with both proof-based and computational work. Optionally, there will be a topic-related project that may develop into a paper for interested students.</p>
            <div style="height: 10px;"></div>
            <table>
                <tr>
                    <th>Resource</th>
                    <th>Title</th>
                    <th>Link</th>
                </tr>
                <tr>
                    <td>Gerstner</td>
                    <td>Neuronal Dynamics</td>
                    <td><a href="https://neuronaldynamics.epfl.ch/online/index.html">Link</a></td>
                </tr>
            </table>
            <div style="height: 30px;"></div>
            <table>
                <tr>
                    <th>Date</th>
                    <th>Topic</th>
                    <th>Speaker</th>
                    <th>Reading</th>
                </tr>
                <tr>
                    <td>October 5th</td>
                    <td>Introduction and Background: Tools of the Trade</td>
                    <td>Shujun</td>
                    <td>Gerstner Chaps. 1-4; [<a href="https://dl.acm.org/doi/abs/10.1145/1007352.1007372">PTHW'21</a>]</td>
                </tr>
                <tr>
                    <td>October 12th</td>
                    <td>Vision: Convolutional Networks and Beyond</td>
                    <td></td>
                    <td>[<a href="https://www.nature.com/articles/nn1199_1019">RP'21</a>]; [<a href="https://www.nature.com/articles/s41467-021-27606-9">BSJKP'21</a>]</td>
                </tr>
                <tr>
                    <td>October 19th</td>
                    <td>Long Short-Term Memory and Transformers</td>
                    <td></td>
                    <td>[<a href="https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735">HS'97</a>]; [<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Vaswani et al. (2017)</a>]; [<a href="https://arxiv.org/abs/2210.05675">CDKKLH'22</a>]</td>
                </tr>
                <tr>
                    <td>October 26th</td>
                    <td>Spiking Neural Networks: Boom or Bust?</td>
                    <td></td>
                    <td>[<a href="https://arxiv.org/abs/1804.08150">TGKMM'19</a>]; [<a href="https://pehlevan.seas.harvard.edu/sites/projects.iq.harvard.edu/files/pehlevan/files/lipehlevan_neurips_2020.pdf">LP'20</a>]</td>
                </tr>
                <tr>
                    <td>November 2nd</td>
                    <td>Attractor Networks: How is memory preserved in networks?</td>
                    <td></td>
                    <td>Gerstner Chap. 17; [<a href="https://journals.aps.org/prx/abstract/10.1103/PhysRevX.13.011009">PAB'23</a>]</td>
                </tr>
                <tr>
                    <td>November 9th</td>
                    <td>Beyond Backpropagation: Deep Learning with Different Learning Rules</td>
                    <td></td>
                    <td>Gerstner Chap. 19; [<a href="https://www.frontiersin.org/articles/10.3389/fncom.2019.00018/full">Amit'19</a>]; [<a href="https://arxiv.org/abs/2209.11883">JRGM'23</a>]</td>
                </tr>
                <tr>
                    <td>November 16th</td>
                    <td>Biologically Constrained Deep Learning</td>
                    <td></td>
                    <td>Gerstner Chap. 20; [<a href="https://pubmed.ncbi.nlm.nih.gov/17079517/">BB'06</a>]; [<a href="https://pubmed.ncbi.nlm.nih.gov/36711468/">SC'23</a>]</td>
                </tr>
                <tr>
                    <td>April 15th</td>
                    <td>Large Language Models and Theory of Mind</td>
                    <td></td>
                    <td>General Discussion</td>
                </tr>
            </table>
        </div>
        
    <hr>
    <h2>Previous Semesters</h2>
    <h2>
        <a href="spring2023.html">Spring 2023</a>    
    <h2>
    <h2>
        <a href="fall2022.html">Fall 2022</a>    
    <h2>
    <h2>
        <a href="summer2022.html">Summer 2022</a>    
    <h2>
    <h2>
        <a href="spring2022.html">Spring 2022</a>    
    <h2>
        <a href="fall2021.html">Fall 2021</a>
    </h2>
    <h2>
        <a href="summer2021.html">Summer 2021</a>
    </h2>
</body>
